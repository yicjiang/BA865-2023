{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOHj2lM7IkZVkziXQDuiS3K"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"kEUXk5xlvg9e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680201823392,"user_tz":240,"elapsed":22400,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"4343186f-d8e4-419b-9291-a2ebb7f564ba"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikeras\n","  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikeras) (1.2.2)\n","Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.9/dist-packages (from scikeras) (23.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.22.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.1.1)\n","Installing collected packages: scikeras\n","Successfully installed scikeras-0.10.0\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n","57026/57026 [==============================] - 0s 0us/step\n"]}],"source":["try:\n","    from scikeras.wrappers import KerasRegressor                     \n","except ImportError:\n","    !pip install scikeras\n","    from scikeras.wrappers import KerasRegressor\n","    \n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import sklearn\n","from sklearn.pipeline import Pipeline # for setting up a pre-processing / tuning pipeline.\n","from sklearn.preprocessing import RobustScaler # Here, we are going to normalize inputs (the ML Pipeline framework from sklearn can implement this.)\n","\n","# So, we are going back to the Boston Housing data here.\n","from tensorflow.keras.datasets import boston_housing\n","(train_data, train_targets), (test_data, test_targets) = (boston_housing.load_data())"]},{"cell_type":"markdown","source":["#*Grid Search CV With Keras Model*"],"metadata":{"id":"Xvf2i7v1zv61"}},{"cell_type":"code","source":["# Make sure you set your custom parameters for training as arguments in your model creation function.\n","def create_model(loss=\"mean_squared_error\",optimizer=\"sgd\",activation=\"relu\",units=100,numLayers=2, batch_size=10):\n","    \n","    # I beleve that you need to explicitly declare an input layer for the scikeras wrapper to work... \n","    model = keras.Sequential([\n","        layers.Input(train_data.shape[1]), \n","        layers.Dense(units, activation=\"relu\")             \n","    ])\n","\n","    if numLayers == 2:\n","        model.add(layers.Dense(units, activation=\"relu\"))\n","\n","    model.add(layers.Dense(1, activation=activation))\n","\n","    model.compile(loss=loss,optimizer=optimizer, metrics=['mse'])\n","    return model\n","\n","# You also need to specify the 'custom' parameters here that you want to add, for them to show up as a trainable parameter in GridSearchCV.\n","regf = KerasRegressor(model=create_model, loss=\"mean_squared_error\", optimizer=\"adam\", activation=\"relu\", units=100, numLayers=2, batch_size=10, verbose=0)\n","\n","# Note you can also do a grid search over an sklearn pipeline, so you can search over diferent types of data pre-processing approaches too!\n","#ml_pipeline = Pipeline([(\"Normalize_with_centering\", RobustScaler()), (\"Model\", regf)])\n","\n","# Here are the configurable parameters we can now search over for either object. \n","print(regf.get_params().keys())\n","#print(ml_pipeline.get_params().keys())"],"metadata":{"id":"dpJeCA_BvdCj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680201979509,"user_tz":240,"elapsed":5,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"92345a8f-17e4-4709-de37-b9be3903006b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'activation', 'units', 'numLayers'])\n"]}]},{"cell_type":"markdown","source":["And this is how I would invoke my grid search... "],"metadata":{"id":"twEp-TV23rUM"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV\n","import numpy as np\n","\n","# Because we are creating the models but are not compiling them yet (we will let the grid fit compile the models on the fly),\n","# this will produce a bunch of warnings. I'm just suppressing the warnings. \n","#import logging, os\n","#logging.disable(logging.WARNING)\n","#os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n","\n","params = {\n","    \"numLayers\": [1,2],\n","    \"units\": [10,50,100,150],\n","    \"activation\": ['relu','selu',None],\n","    \"batch_size\": [25,50],\n","    \"epochs\": [10,20,30]\n","}\n","\n","params_pipe = {\n","    \"Model__numLayers\": [1,2],\n","    \"Model__units\": [10,100,500],\n","    \"Model__activation\": ['relu','selu',None],\n","    \"Model__batch_size\": [25,50],\n","    \"Model__epochs\":[10,20,30]\n","}\n","\n","grid = GridSearchCV(regf, params, scoring='neg_mean_absolute_error',verbose=0,cv=10)\n","#grid = GridSearchCV(ml_pipeline, params_pipe, scoring='neg_mean_absolute_error',verbose=0,cv=10)\n","\n","grid.fit(train_data, train_targets)"],"metadata":{"id":"CLhnTa921I0-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"85f16d1a-710f-4cd2-ab30-2d76e618ab49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa0002dcdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9f843a4d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]}]},{"cell_type":"markdown","source":["I can then extract the parameters that yielded the top performance... "],"metadata":{"id":"L-ZBoMDM3wKF"}},{"cell_type":"code","source":["print(f\"Best Score  : {grid.best_score_}\")\n","print(f\"Best Params : {grid.best_params_}\")"],"metadata":{"id":"UISkU-jewLVB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680202120461,"user_tz":240,"elapsed":4,"user":{"displayName":"Gordon Burtch","userId":"10144756805379529333"}},"outputId":"b81417cc-910e-400f-dc24-a66472bb4112"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Score  : -22.398225308641976\n","Best Params : {'activation': 'relu', 'numLayers': 1, 'units': 10}\n"]}]},{"cell_type":"markdown","source":["Finally, a little function that looks at pairs of parameter values, and the associated model performance, holding all other parameters to their ideal values. "],"metadata":{"id":"F8X2ajBn32fa"}}]}